---
layout: post
title: 201705 阅读笔记
category: 阅读笔记
tagline: 
tags: [阅读笔记, automatic differentiation, AutoDiff, 自动梯度求解, 神经网络, 深度学习]
theme :
  name : bootstrap-3
---
{% include JB/setup %}

## AutoDiff (Automatic Differentiation, 自动梯度求解)

在机器学习领域，梯度是一个非常基本的概念。在计算流体力学、核能工程、大气科学等领域，自动梯度求解是常用的工具，在这些领域使用自动梯度求解工具的频度超过了在机器学习领域使用的频度。随着深度学习技术的兴起，越来越多的深度模型被提出，有了自动梯度求解工具后，研究员和工程师可以专注于问题建模，而可以不用太关注参数优化问题。

神经网络中的误差反传算法（Back Propagation）只是AutoDiff的一个特例，而且由于在神经网络中输入变量一般要比输出变量多不少，所以会常用到AutoDiff的reverse版本。

[Automatic Differentiation](http://dlsys.cs.washington.edu/pdf/lecture4.pdf) 来自 Tianqi Chen 在华盛顿大学的 "Deep Learning System" 课程
+ 用简洁的语言对比了 Numerical Differentiation, Symbolic Differentiation 和 AutoDiff ，并用具体的例子介绍 AutoDiff in forward mode 和 AutoDiff in backward mode。
  - Numerical differentiation，容易碰到round error
  - Symbolic differentiation，需要用大量的存储空间来存储中间的计算公式，而且需要给出完整的求梯度公式。在实际应用中该方案会比较浪费资源。
  - Automatic differentiation (AutoDiff)，一种较好的实现策略。可以视其为动态规划算法，其 Forward mode 和 backward mode 跟HMM的前向算法和后向算法比较类似，所以其核心思想比较好理解。如果希望更详细的理解AutoDiff，可以阅读 [Automatic differentiation in machine learning: a survey](https://arxiv.org/abs/1502.05767) 这篇paper。

* * *

**原创文章，转载请注明：**转载自[{{ site.title }}]({{ site.production_url }})

**本文链接地址：**[{{ page.title }}]({{ site.production_url }}{{ page.url }})

* * *
